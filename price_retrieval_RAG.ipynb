{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlNou30bjAzJ+vKUGfAd3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alecarini/HLT-Project-Exam/blob/main/price_retrieval_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjqnM0p4z93L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import process\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import openai\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "openai.api_key = \"key\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lsrFg74V0I3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "\n",
        "# Load dataset\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load dataset from an Excel file.\"\"\"\n",
        "    return pd.read_excel(file_path)\n",
        "\n",
        "# Create FAISS index\n",
        "def create_faiss_index(df):\n",
        "    \"\"\"Create FAISS vector index for retrieval.\"\"\"\n",
        "    df['text'] = df['medical_service'] + ' ' + df['speciality']\n",
        "    loader = DataFrameLoader(df[['text', 'min_price', 'max_price']], page_content_column='text')\n",
        "    documents = loader.load()\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# Retrieve similar entries\n",
        "def retrieve_similar(service, speciality, vectorstore):\n",
        "    \"\"\"Retrieve similar cases using FAISS.\"\"\"\n",
        "    query = f\"{service} {speciality}\"\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    if docs:\n",
        "        best_match = docs[0].metadata  # Best retrieved document\n",
        "        return best_match['min_price'], best_match['max_price'], \"dataset\", 10.0\n",
        "    return None, None, None, 0\n",
        "\n",
        "# Generate price with OpenAI\n",
        "def generate_price_with_openai(service, speciality, context=\"\"):\n",
        "    \"\"\"Use OpenAI to generate a price estimate when no dataset match is found.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"Sei un esperto in tariffe mediche in Italia.\n",
        "        Basandoti esclusivamente sul seguente contesto e sulla richiesta, fornisci il range di prezzo medio.\n",
        "\n",
        "        Contesto:\n",
        "        {context}\n",
        "\n",
        "        Richiesta:\n",
        "        Medical Service: {service}\n",
        "        Speciality: {speciality}\n",
        "\n",
        "        Rispondi SOLO con una stringa nel formato esatto:\n",
        "        {{ min_price=X, max_price=Y, source=openai, confidence=C }}\n",
        "        \"\"\"\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"system\", \"content\": prompt}]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "# Main function to get price\n",
        "def get_price(service, speciality, vectorstore):\n",
        "    \"\"\"Retrieve or generate price estimate.\"\"\"\n",
        "    min_price, max_price, source, confidence = retrieve_similar(service, speciality, vectorstore)\n",
        "    if source:\n",
        "        return f\"{{ min_price={min_price}, max_price={max_price}, source={source}, confidence={confidence} }}\"\n",
        "\n",
        "    return generate_price_with_openai(service, speciality)\n",
        "\n",
        "# Example usage\n",
        "df = load_data(\"medical_prices.xlsx\")\n",
        "vectorstore = create_faiss_index(df)\n",
        "result = get_price(\"Visita dermatologica\", \"Dermatologia\", vectorstore)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "WSFhmWzr0JbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}