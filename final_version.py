# -*- coding: utf-8 -*-
"""Codice pazzo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFhDgd6aCfDD27Cc2jHWMskyZJO2CIMm
"""

import pandas as pd
df= pd.read_csv('data_to_be_cleansed.csv')
df.head()

# Group non-anxiety/depression conditions into 'other'
df['target'] = df['target'].replace({0: 'other', 2: 'other', 3: 'other', 4: 'anxiety', 1: 'depression'})

df['text']=df['text'].astype(str)

import re
import nltk
from nltk.corpus import stopwords
import pandas as pd

nltk.download('stopwords')
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)  # punteggiatura
    text = text.lower()  # minuscolo
    text = ' '.join(word for word in text.split() if word not in stopwords.words('english'))
    return text

df['cleaned_text']=df['text'].apply(clean_text)

from nltk.tokenize import word_tokenize
nltk.download('punkt')

def tokenize_text(text):
  tokens = word_tokenize(text)
  return tokens

df['text_ready']=df['text'].apply(tokenize_text)
print(df['text_ready'])

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from scipy.sparse import hstack

#Create TF-IDF Features
tfidf = TfidfVectorizer(max_features=5000, min_df=5)
X_tfidf = tfidf.fit_transform(df['cleaned_text'])

y = df['target']

X_train_val, X_test, y_train_val, y_test = train_test_split(X_combined, y, test_size=0.1, random_state=42)

X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1111, random_state=42)

# Model training
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Results with TF-IDF only:")
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

word_list = [
  "eat", "play" "feel", "want", "need", "think", "believe", "hope",
    "cry", "worry", "panic", "tired", "sad", "anxious",
    "nervous", "hopeless", "helpless", "fullest", "sad", "tired", "exhausted"
    "less", "worse", "better", "smaller", "bigger", "least", "most", "worst", "ed", "sleep", "beg", "i"
    "relieved", "hopeful", "satisfied", "hurt", "hate", "delusional", "tough", "despair", "nightmare",
    "worthless", "frustrated", "angry", "lonely", "scared", "depressed",
    "worried", "panicked", "nervous", "fearful", "uneasy", "restless",
    "tense", "apprehensive", "dread", "kill", "annoyed", "mad", "enraged", "despair", "die", "anymore"
    "sorrowful", "downcast", "melancholy", "tearful", "warrior", "escape",
    "did", "studied", "graduated", "went", "saw", "thought", "felt",
    "wanted", "starts", "feels", "says", "believes", "struggles", "chest", "heart"
    "plan", "intend", "expect", "hell", "damn", "crap", "all", "never", "absolutely", "always",
    "every", "must", "entirely", "completely", "forever", "nobody", "harm", "death", "dead", "existence", "selfharm", "destroyed", "alone", "lonely", "loneliness",
]
# creation of a feature from the word list
def count_words(text, word_list):
    tokens = word_tokenize(text.lower())
    return sum(1 for word in tokens if word in word_list)

df['word_list_count'] = df['cleaned_text'].apply(lambda text: count_words(text, word_list))

# combination of features
X_combined = hstack([X_tfidf, df[['word_list_count']].values])
y = df['target']

X_train_val, X_test, y_train_val, y_test = train_test_split(X_combined, y, test_size=0.1, random_state=42)

X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1111, random_state=42)


model_combined = RandomForestClassifier(random_state=42)
model_combined.fit(X_train_combined, y_train_combined)
y_pred_combined = model_combined.predict(X_test_combined)


y_pred_combined = model_combined.predict(X_test_combined)
print("Results with TF-IDF and Word List:")
print("Classification Report:\n", classification_report(y_test_combined, y_pred_combined))
print("Confusion Matrix:\n", confusion_matrix(y_test_combined, y_pred_combined))
print("Accuracy:", accuracy_score(y_test_combined, y_pred_combined))

len(word_list)

importances = model_combined.feature_importances_


tfidf_feature_names = tfidf.get_feature_names_out()
all_feature_names = list(tfidf_feature_names) + ['word_list_count']
feature_importances = pd.DataFrame({
    'Feature': all_feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)
print(feature_importances.head(20))

# Test!
def preprocess_input(text):
    text = re.sub(r'[^\w\s]', '', text)
    text = text.lower()
    text = ' '.join(word for word in text.split() if word not in stopwords.words('english'))


    tokens = word_tokenize(text)
    return text, tokens


def transform_input(text, tokens):

    text_tfidf = tfidf.transform([text])

 #count the number of words from the word list
word_list_count = sum(1 for word in tokens if word in word_list)


combined_features = hstack([text_tfidf, [[word_list_count]]])

    return combined_features


def predict_category(text):
    preprocessed_text, tokens = preprocess_input(text)
    features = transform_input(preprocessed_text, tokens)
    prediction = model_combined.predict(features)

    return prediction[0]

# Example of use
test_text = "I feel lost"
predicted_category = predict_category(test_text)
print(f"The predicted category for the sentence is: {predicted_category}")